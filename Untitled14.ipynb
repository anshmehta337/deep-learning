{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi2HiAv2Sl6c2K6yn0A8hW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshmehta337/deep-learning/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XkkhiBYyEc4h"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "class earlystop:\n",
        "  def __init__(self,patience=1,minde=0,path='checkpoint.pt'):\n",
        "    self.patience=patience\n",
        "    self.minde=minde\n",
        "    self.cnt=0\n",
        "    self.path=path\n",
        "    self.min_validation_loss = float('inf')\n",
        "  def early_stop(self,val_loss,model):\n",
        "    if val_loss<self.min_validation_loss:\n",
        "      self.min_validation_loss=val_loss\n",
        "      self.save_checkpoint(model)\n",
        "      self.cnt=0\n",
        "    elif val_loss>self.min_validation_loss+self.minde:\n",
        "      self.cnt+=1\n",
        "      if(self.cnt>self.patience):\n",
        "        return True\n",
        "    return False\n",
        "  def save_checkpoint(self,model):\n",
        "    torch.save(model.state_dict(),self.path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we have done implementing early stopping"
      ],
      "metadata": {
        "id": "rv0blLHyFp5A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have to work on implementing l1 and l2 regularization"
      ],
      "metadata": {
        "id": "lgO8GpFhGE2B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "class DiabetesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 32)\n",
        "        self.act1 = nn.LeakyReLU(0.3)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.act2 = nn.LeakyReLU(0.1)\n",
        "        self.out = nn.Linear(16, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.act2(self.fc2(x))\n",
        "        x = self.sigmoid(self.out(x))\n",
        "        return x\n",
        "model = DiabetesModel()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
        "#declaration of l2 using weight decay"
      ],
      "metadata": {
        "id": "g7o0Dn62G7bv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1_lambda = 1e-5  # L1 regularization strength\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    # Compute L1 regularization\n",
        "    l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "    loss = loss + l1_lambda * l1_norm\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "D5kfnZwYMz9w",
        "outputId": "d4868344-73ea-4747-807c-809792cebe29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4215916811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml1_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m  \u001b[0;31m# L1 regularization strength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ei580t2NeRv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}